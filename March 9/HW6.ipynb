{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                             HW 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import Scraper as scraper\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from nltk.metrics import *\n",
    "from nltk.classify import NaiveBayesClassifier as NB\n",
    "from nltk import word_tokenize, FreqDist,classify\n",
    "import collections\n",
    "\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "import itertools\n",
    "from nltk import word_tokenize, FreqDist, classify, ConditionalFreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>companyname</th>\n",
       "      <th>Year</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000950123-10-115038.txt</td>\n",
       "      <td>American Pacific Corporation</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000950129-06-002726.txt</td>\n",
       "      <td>FREMONT GENERAL CORP</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000950134-09-004608.txt</td>\n",
       "      <td>UNITED STATES LIME &amp; MINERALS INC</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000950152-07-001610.txt</td>\n",
       "      <td>LUBRIZOL CORP</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000807397-98-000073.txt</td>\n",
       "      <td>MARK SOLUTIONS INC</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename                        companyname  Year  pos\n",
       "0  0000950123-10-115038.txt       American Pacific Corporation  2010    1\n",
       "1  0000950129-06-002726.txt               FREMONT GENERAL CORP  2005    1\n",
       "2  0000950134-09-004608.txt  UNITED STATES LIME & MINERALS INC  2008    0\n",
       "3  0000950152-07-001610.txt                      LUBRIZOL CORP  2006    1\n",
       "4  0000807397-98-000073.txt                 MARK SOLUTIONS INC  1998    0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel('files/Labeling results.xlsx')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of the MDAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_MDA(filename):\n",
    "    # Credits for the scraper package go to GROUP 7\n",
    "    mda_text = ''\n",
    "    with open('files/' + filename) as file:\n",
    "        soup = BeautifulSoup(file, \"lxml\")\n",
    "        \n",
    "        # We first try the scrape by regex method\n",
    "        try:\n",
    "            mda_text = scraper.scrapeByRegex(soup)\n",
    "            if mda_text:\n",
    "                mda_text = BeautifulSoup(mda_text, \"html.parser\").get_text()\n",
    "                mda_text = re.sub('[^\\w]', ' ', mda_text)\n",
    "                return mda_text\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # We then try the scrapeByAnchorTag method if the previous method didn;t work\n",
    "        try:\n",
    "            mda_text = scraper.scrapeByAnchorTag(soup)\n",
    "            if mda_text:\n",
    "                mda_text = BeautifulSoup(mda_text, \"html.parser\").get_text()\n",
    "                mda_text = re.sub('[^\\w]', ' ', mda_text)\n",
    "                return mda_text\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>companyname</th>\n",
       "      <th>Year</th>\n",
       "      <th>pos</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000950123-10-115038.txt</td>\n",
       "      <td>American Pacific Corporation</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>Item 7  Management s     Discussion and Analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000950129-06-002726.txt</td>\n",
       "      <td>FREMONT GENERAL CORP</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>Item 7  Management s Discussion and Analysis o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000950134-09-004608.txt</td>\n",
       "      <td>UNITED STATES LIME &amp; MINERALS INC</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>ITEM 7      MANAGEMENT S     DISCUSSION AND AN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000950152-07-001610.txt</td>\n",
       "      <td>LUBRIZOL CORP</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>ITEM 7    MANAGEMENT S DISCUSSION AND ANALYSIS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000807397-98-000073.txt</td>\n",
       "      <td>MARK SOLUTIONS INC</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>Item 7   Management s Discussion and Analysis ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename                        companyname  Year  pos  \\\n",
       "0  0000950123-10-115038.txt       American Pacific Corporation  2010    1   \n",
       "1  0000950129-06-002726.txt               FREMONT GENERAL CORP  2005    1   \n",
       "2  0000950134-09-004608.txt  UNITED STATES LIME & MINERALS INC  2008    0   \n",
       "3  0000950152-07-001610.txt                      LUBRIZOL CORP  2006    1   \n",
       "4  0000807397-98-000073.txt                 MARK SOLUTIONS INC  1998    0   \n",
       "\n",
       "                                                text  \n",
       "0  Item 7  Management s     Discussion and Analys...  \n",
       "1  Item 7  Management s Discussion and Analysis o...  \n",
       "2  ITEM 7      MANAGEMENT S     DISCUSSION AND AN...  \n",
       "3  ITEM 7    MANAGEMENT S DISCUSSION AND ANALYSIS...  \n",
       "4  Item 7   Management s Discussion and Analysis ...  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'] = dataset.filename.apply(extract_MDA)\n",
    "dataset.dropna(inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We split the dataset in train/test ratio: 0.30\n",
    "train_set, test_set = train_test_split(dataset, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5580\n",
      "[u'four', u'increase', u'granting', u'eligible', u'electricity', u'xto', u'chirally', u'sinking', u'regional', u'dell', u'pigment', u'appropriation', u'bringing', u'internally', u'bioplastics', u'specialties', u'straight', u'specially', u'paperage', u'feasibility', u'second', u'errors', u'contributed', u'bonuses', u'fossil', u'increasing', u'agreement', u'affiliates', u'reprogrammed', u'china', u'affiliated', u'borrowers', u'cyclical', u'k', u'deferring', u'reports', u'military', u'cancellation', u'appropriately', u'classification', u'explained', u'replace', u'brought', u'pound', u'unit', u'derivatives', u'dnl', u'century', u'therefore', u'strike']\n"
     ]
    }
   ],
   "source": [
    "train_set_words = []\n",
    "\n",
    "for mda in train_set.text.values:\n",
    "    words = word_tokenize(mda)\n",
    "    for word in words:\n",
    "        stand_word = word.lower() \n",
    "        if ((not re.search(r'[0-9]', stand_word)) and (stand_word not in train_set_words)):\n",
    "                      train_set_words.append(stand_word)\n",
    "\n",
    "all_words = list(set(train_set_words))\n",
    "print(len(all_words))\n",
    "print(all_words[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mda_features(mda):\n",
    "    mda_words = word_tokenize(mda.text)\n",
    "    features = {}\n",
    "    stand_mda_words = [word.lower() for word in mda_words]\n",
    "    for word in all_words:\n",
    "        features['contains({})'.format(word)] = word in mda_words\n",
    "    return (features, mda.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_train_set = train_set.apply(mda_features,axis=1)\n",
    "classifier = NB.train(feature_train_set)\n",
    "feature_test_set = test_set.apply(mda_features,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "         contains(apply) = True                1 : 0      =      5.9 : 1.0\n",
      "      contains(improved) = True                1 : 0      =      5.9 : 1.0\n",
      "         contains(eight) = True                1 : 0      =      5.9 : 1.0\n",
      "      contains(maturity) = True                1 : 0      =      5.9 : 1.0\n",
      "    contains(reasonably) = True                1 : 0      =      5.9 : 1.0\n",
      "      contains(reducing) = True                1 : 0      =      5.3 : 1.0\n",
      "         contains(ratio) = True                1 : 0      =      5.3 : 1.0\n",
      "contains(transportation) = True                1 : 0      =      5.3 : 1.0\n",
      "      contains(unfunded) = True                1 : 0      =      5.3 : 1.0\n",
      "  contains(successfully) = True                1 : 0      =      4.7 : 1.0\n",
      "        contains(health) = True                1 : 0      =      4.7 : 1.0\n",
      "           contains(gas) = True                1 : 0      =      4.7 : 1.0\n",
      "        contains(expand) = True                1 : 0      =      4.7 : 1.0\n",
      "      contains(outcomes) = True                1 : 0      =      4.7 : 1.0\n",
      "        contains(plants) = True                1 : 0      =      4.7 : 1.0\n",
      "         contains(types) = True                1 : 0      =      4.7 : 1.0\n",
      "       contains(leading) = True                1 : 0      =      4.7 : 1.0\n",
      "        contains(energy) = True                1 : 0      =      4.7 : 1.0\n",
      "   contains(limitations) = True                1 : 0      =      4.7 : 1.0\n",
      "          contains(does) = False               1 : 0      =      4.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.62      0.62         8\n",
      "          1       0.25      0.25      0.25         4\n",
      "\n",
      "avg / total       0.50      0.50      0.50        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set_pred = classifier.classify_many([fs for (fs, l) in feature_test_set])\n",
    "print(\"Accuracy: {}\".format(classify.accuracy(classifier, feature_test_set)))\n",
    "print(classification_report(test_set.pos, test_set_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement number 1: Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mda_features_bis(mda):\n",
    "    mda_words = word_tokenize(mda.text)\n",
    "    stand_mda_words = [word.lower() for word in mda_words]\n",
    "    bigram_finder = BigramCollocationFinder.from_words(stand_mda_words)\n",
    "    score_fn = BigramAssocMeasures.chi_sq\n",
    "    bigrams = bigram_finder.nbest(score_fn, 100)\n",
    "    return (dict([(ngram, True) for ngram in itertools.chain(stand_mda_words, bigrams)]),mda.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_train_set = train_set.apply(mda_features_bis,axis=1)\n",
    "classifier2 = NB.train(feature_train_set)\n",
    "feature_test_set = test_set.apply(mda_features,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              reasonably = True                1 : 0      =      5.9 : 1.0\n",
      "                    safe = True                1 : 0      =      5.9 : 1.0\n",
      "                improved = True                1 : 0      =      5.9 : 1.0\n",
      "                   apply = True                1 : 0      =      5.9 : 1.0\n",
      "                   eight = True                1 : 0      =      5.9 : 1.0\n",
      "                computer = True                0 : 1      =      5.4 : 1.0\n",
      "             disclosures = None                0 : 1      =      5.4 : 1.0\n",
      "                adjusted = True                1 : 0      =      5.3 : 1.0\n",
      "                unfunded = True                1 : 0      =      5.3 : 1.0\n",
      "            registration = True                1 : 0      =      5.3 : 1.0\n",
      "          transportation = True                1 : 0      =      5.3 : 1.0\n",
      "                reducing = True                1 : 0      =      5.3 : 1.0\n",
      "                   ratio = True                1 : 0      =      5.3 : 1.0\n",
      "                     109 = True                1 : 0      =      5.3 : 1.0\n",
      "                 leading = True                1 : 0      =      4.7 : 1.0\n",
      "                  health = True                1 : 0      =      4.7 : 1.0\n",
      "                   types = True                1 : 0      =      4.7 : 1.0\n",
      "               commenced = True                1 : 0      =      4.7 : 1.0\n",
      "                   facts = True                1 : 0      =      4.7 : 1.0\n",
      "                  expand = True                1 : 0      =      4.7 : 1.0\n",
      "                      vs = True                1 : 0      =      4.7 : 1.0\n",
      "            successfully = True                1 : 0      =      4.7 : 1.0\n",
      "                  course = True                1 : 0      =      4.7 : 1.0\n",
      "             limitations = True                1 : 0      =      4.7 : 1.0\n",
      "                     132 = True                1 : 0      =      4.7 : 1.0\n",
      "                  energy = True                1 : 0      =      4.7 : 1.0\n",
      "                 offices = True                1 : 0      =      4.7 : 1.0\n",
      "                  plants = True                1 : 0      =      4.7 : 1.0\n",
      "                    home = True                1 : 0      =      4.7 : 1.0\n",
      "                   audit = True                1 : 0      =      4.7 : 1.0\n",
      "                 penalty = True                1 : 0      =      4.7 : 1.0\n",
      "                     gas = True                1 : 0      =      4.7 : 1.0\n",
      "              industrial = True                1 : 0      =      4.7 : 1.0\n",
      "                     101 = True                1 : 0      =      4.7 : 1.0\n",
      "                outcomes = True                1 : 0      =      4.7 : 1.0\n",
      "                maintain = None                0 : 1      =      4.6 : 1.0\n",
      "                   level = None                0 : 1      =      4.6 : 1.0\n",
      "                 partner = True                0 : 1      =      4.6 : 1.0\n",
      "                     our = None                0 : 1      =      4.6 : 1.0\n",
      "                   taxes = None                0 : 1      =      4.6 : 1.0\n",
      "                mortgage = True                0 : 1      =      4.6 : 1.0\n",
      "(u'foreign', u'currency') = True                0 : 1      =      4.6 : 1.0\n",
      "                internet = True                0 : 1      =      4.6 : 1.0\n",
      "                hardware = True                0 : 1      =      4.6 : 1.0\n",
      "              principles = None                0 : 1      =      4.5 : 1.0\n",
      "                    2000 = None                1 : 0      =      4.3 : 1.0\n",
      "            indebtedness = True                1 : 0      =      4.3 : 1.0\n",
      "              reasonable = None                0 : 1      =      4.1 : 1.0\n",
      "                    2006 = None                0 : 1      =      4.1 : 1.0\n",
      "              efficiency = True                1 : 0      =      4.0 : 1.0\n",
      "                     165 = True                1 : 0      =      4.0 : 1.0\n",
      "              separately = True                1 : 0      =      4.0 : 1.0\n",
      "              consistent = True                1 : 0      =      4.0 : 1.0\n",
      "                    does = None                1 : 0      =      4.0 : 1.0\n",
      "              conversion = True                1 : 0      =      4.0 : 1.0\n",
      "                bulletin = True                1 : 0      =      4.0 : 1.0\n",
      "                downward = True                1 : 0      =      4.0 : 1.0\n",
      "                 prevent = True                1 : 0      =      4.0 : 1.0\n",
      "              negatively = True                1 : 0      =      4.0 : 1.0\n",
      "                    fuel = True                1 : 0      =      4.0 : 1.0\n",
      "                   serve = True                1 : 0      =      4.0 : 1.0\n",
      "                  reform = True                1 : 0      =      4.0 : 1.0\n",
      "               integrate = True                1 : 0      =      4.0 : 1.0\n",
      "                   prime = True                1 : 0      =      4.0 : 1.0\n",
      "             proprietary = True                1 : 0      =      4.0 : 1.0\n",
      "                  almost = True                1 : 0      =      4.0 : 1.0\n",
      "              quantities = True                1 : 0      =      4.0 : 1.0\n",
      "              definition = True                1 : 0      =      4.0 : 1.0\n",
      "                     345 = True                1 : 0      =      4.0 : 1.0\n",
      "                 arising = True                1 : 0      =      4.0 : 1.0\n",
      "                supplies = True                1 : 0      =      4.0 : 1.0\n",
      "                coverage = True                1 : 0      =      4.0 : 1.0\n",
      "               affecting = True                1 : 0      =      4.0 : 1.0\n",
      "                  upward = True                1 : 0      =      4.0 : 1.0\n",
      "             effectively = True                1 : 0      =      4.0 : 1.0\n",
      "                 defines = True                1 : 0      =      4.0 : 1.0\n",
      "                 demands = True                1 : 0      =      4.0 : 1.0\n",
      "    (u'natural', u'gas') = True                1 : 0      =      4.0 : 1.0\n",
      "                original = True                1 : 0      =      4.0 : 1.0\n",
      "               partially = None                0 : 1      =      3.9 : 1.0\n",
      "        (u'june', u'30') = True                0 : 1      =      3.9 : 1.0\n",
      "(u'restructuring', u'accrual') = True                0 : 1      =      3.9 : 1.0\n",
      "(u'economic', u'conditions') = True                0 : 1      =      3.9 : 1.0\n",
      "                 western = True                0 : 1      =      3.9 : 1.0\n",
      "(u'necessarily', u'indicative') = True                0 : 1      =      3.9 : 1.0\n",
      "               datapoint = True                0 : 1      =      3.9 : 1.0\n",
      "    (u'market', u'risk') = True                0 : 1      =      3.9 : 1.0\n",
      "(u'regulations', u'applicable') = True                0 : 1      =      3.9 : 1.0\n",
      "                     139 = True                0 : 1      =      3.9 : 1.0\n",
      "    (u'federal', u'tax') = True                0 : 1      =      3.9 : 1.0\n",
      "               exclusive = True                0 : 1      =      3.9 : 1.0\n",
      "                    york = True                0 : 1      =      3.9 : 1.0\n",
      "(u'competition', u'economic') = True                0 : 1      =      3.9 : 1.0\n",
      "                 florida = True                0 : 1      =      3.9 : 1.0\n",
      "    (u'san', u'antonio') = True                0 : 1      =      3.9 : 1.0\n",
      "                   owing = True                0 : 1      =      3.9 : 1.0\n",
      "    (u'they', u'relate') = True                0 : 1      =      3.9 : 1.0\n",
      "             rollforward = True                0 : 1      =      3.9 : 1.0\n",
      "(u'preferred', u'stock') = True                0 : 1      =      3.9 : 1.0\n",
      "     (u'many', u'cases') = True                0 : 1      =      3.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier2.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         8\n",
      "          1       0.33      1.00      0.50         4\n",
      "\n",
      "avg / total       0.11      0.33      0.17        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set_pred = classifier2.classify_many([fs for (fs, l) in feature_test_set])\n",
    "print(\"Accuracy: {}\".format(classify.accuracy(classifier2, feature_test_set)))\n",
    "print(classification_report(test_set.pos, test_set_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement number 2: Reducing feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_fd = FreqDist()\n",
    "label_word_fd = ConditionalFreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in train_set.iterrows():\n",
    "    mdatxt = row[1]['text']\n",
    "    stand_mdatxt = mdatxt.lower()\n",
    "    mda_words = word_tokenize(mdatxt)\n",
    "    word_fd.update(mda_words)\n",
    "    if (row[1]['pos'] ==1):\n",
    "        label_word_fd['pos'].update(mda_words)\n",
    "    else:\n",
    "        label_word_fd['neg'].update(mda_words)\n",
    "    \n",
    "pos_word_count = label_word_fd['pos'].N()\n",
    "neg_word_count = label_word_fd['neg'].N()\n",
    "total_word_count = pos_word_count + neg_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_scores = {}\n",
    " \n",
    "for word, freq in word_fd.iteritems():\n",
    "    pos_score = BigramAssocMeasures.chi_sq(label_word_fd['pos'][word],\n",
    "        (freq, pos_word_count), total_word_count)\n",
    "    neg_score = BigramAssocMeasures.chi_sq(label_word_fd['neg'][word],\n",
    "        (freq, neg_word_count), total_word_count)\n",
    "    word_scores[word] = pos_score + neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'Folio', u'End', u'No', u'year', u'Field', u'Ely', u'type', u'Body', u'Begin', u'PRC', u'Company', u'recorded', u's', u'shares', u'payments', u'ASC', u'of', u'Hamilton', u'LLC', u'2006', u'2011', u'2010', u'Kinross', u'stock', u'DHI', u'December', u'Head', u'Mt', u'000', u'PBM', u'during', u'segment', u'properties', u'colindex', u'1997', u'ended', u'1999', u'1998', u'Sequence', u'MH', u'joint', u'Collar', u'2000', u'2001', u'exploration', u'2007', u'2004', u'2005', u'Table', u'the'])\n"
     ]
    }
   ],
   "source": [
    "best = sorted(word_scores.iteritems(), key=lambda (w,s): s, reverse=True)[:50]\n",
    "bestwords = set([w for w, s in best])\n",
    "print bestwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mda_features_ter(mda):\n",
    "    mda_words = word_tokenize(mda.text)\n",
    "    features = {}\n",
    "    stand_mda_words = [word.lower() for word in mda_words]\n",
    "    for word in all_words:\n",
    "        if word in bestwords:\n",
    "            features['contains({})'.format(word)] = word in mda_words\n",
    "    return (features, mda.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_train_set = train_set.apply(mda_features_ter,axis=1)\n",
    "classifier3 = NB.train(feature_train_set)\n",
    "feature_test_set = test_set.apply(mda_features,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "      contains(colindex) = True                1 : 0      =      2.8 : 1.0\n",
      "       contains(segment) = True                1 : 0      =      2.8 : 1.0\n",
      "      contains(payments) = False               0 : 1      =      2.5 : 1.0\n",
      "         contains(joint) = True                0 : 1      =      2.4 : 1.0\n",
      "         contains(stock) = False               0 : 1      =      1.8 : 1.0\n",
      "    contains(properties) = True                1 : 0      =      1.7 : 1.0\n",
      "          contains(type) = True                1 : 0      =      1.7 : 1.0\n",
      "        contains(shares) = False               1 : 0      =      1.7 : 1.0\n",
      "       contains(segment) = False               0 : 1      =      1.6 : 1.0\n",
      "         contains(joint) = False               1 : 0      =      1.4 : 1.0\n",
      "    contains(properties) = False               0 : 1      =      1.3 : 1.0\n",
      "          contains(type) = False               0 : 1      =      1.3 : 1.0\n",
      "      contains(colindex) = False               0 : 1      =      1.3 : 1.0\n",
      "      contains(payments) = True                1 : 0      =      1.2 : 1.0\n",
      "        contains(shares) = True                0 : 1      =      1.2 : 1.0\n",
      "         contains(ended) = True                0 : 1      =      1.2 : 1.0\n",
      "         contains(stock) = True                1 : 0      =      1.1 : 1.0\n",
      "   contains(exploration) = True                0 : 1      =      1.1 : 1.0\n",
      "      contains(recorded) = True                0 : 1      =      1.1 : 1.0\n",
      "        contains(during) = True                0 : 1      =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier3.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.75      0.75         8\n",
      "          1       0.50      0.50      0.50         4\n",
      "\n",
      "avg / total       0.67      0.67      0.67        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set_pred = classifier3.classify_many([fs for (fs, l) in feature_test_set])\n",
    "print(\"Accuracy: {}\".format(classify.accuracy(classifier3, feature_test_set)))\n",
    "print(classification_report(test_set.pos, test_set_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
