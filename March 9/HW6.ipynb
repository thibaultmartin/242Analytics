{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import Scraper as scraper\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.metrics import *\n",
    "from nltk.classify import NaiveBayesClassifier as NB\n",
    "from nltk import word_tokenize, FreqDist,classify, ConditionalFreqDist, pos_tag\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "\n",
    "import collections\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the 40 10K documents of last week, we ADDED 29 extra 10K documents in order to get a bigger dataset. In this case, we used the stock price annual return value of the 10K file in order to determine the sentiment [positive/negative]. If the annual return is negative, then the sentiment will be accordingly negative, and viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>companyname</th>\n",
       "      <th>year</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000950123-10-115038.txt</td>\n",
       "      <td>American Pacific Corporation</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000950129-06-002726.txt</td>\n",
       "      <td>FREMONT GENERAL CORP</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000950134-09-004608.txt</td>\n",
       "      <td>UNITED STATES LIME &amp; MINERALS INC</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000950152-07-001610.txt</td>\n",
       "      <td>LUBRIZOL CORP</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000807397-98-000073.txt</td>\n",
       "      <td>MARK SOLUTIONS INC</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename                        companyname  year  pos\n",
       "0  0000950123-10-115038.txt       American Pacific Corporation  2010    1\n",
       "1  0000950129-06-002726.txt               FREMONT GENERAL CORP  2005    1\n",
       "2  0000950134-09-004608.txt  UNITED STATES LIME & MINERALS INC  2008    0\n",
       "3  0000950152-07-001610.txt                      LUBRIZOL CORP  2006    1\n",
       "4  0000807397-98-000073.txt                 MARK SOLUTIONS INC  1998    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel('files/Labeling results.xlsx')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of the MDAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_MDA(filename):\n",
    "    # Credits for the scraper package go to GROUP 7\n",
    "    mda_text = ''\n",
    "    with open('files/' + filename) as file:\n",
    "        soup = BeautifulSoup(file, \"lxml\")\n",
    "        \n",
    "        # We first try the scrape by regex method\n",
    "        try:\n",
    "            mda_text = scraper.scrapeByRegex(soup)\n",
    "            if mda_text:\n",
    "                mda_text = BeautifulSoup(mda_text, \"html.parser\").get_text()\n",
    "                mda_text = re.sub('[^\\w]', ' ', mda_text)\n",
    "                mda_text = re.sub(\"\\d+\",\"\",mda_text)\n",
    "                return mda_text\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # We then try the scrapeByAnchorTag method if the previous method didn;t work\n",
    "        try:\n",
    "            mda_text = scraper.scrapeByAnchorTag(soup)\n",
    "            if mda_text:\n",
    "                mda_text = BeautifulSoup(mda_text, \"html.parser\").get_text()\n",
    "                mda_text = re.sub('[^\\w]', ' ', mda_text)\n",
    "                mda_text = re.sub(\"\\d+\",\"\",mda_text)\n",
    "                return mda_text\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>companyname</th>\n",
       "      <th>year</th>\n",
       "      <th>pos</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000950123-10-115038.txt</td>\n",
       "      <td>American Pacific Corporation</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>Item   Management s     Discussion and Analysi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000950129-06-002726.txt</td>\n",
       "      <td>FREMONT GENERAL CORP</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>Item   Management s Discussion and Analysis of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000950134-09-004608.txt</td>\n",
       "      <td>UNITED STATES LIME &amp; MINERALS INC</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>ITEM       MANAGEMENT S     DISCUSSION AND ANA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000950152-07-001610.txt</td>\n",
       "      <td>LUBRIZOL CORP</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>ITEM     MANAGEMENT S DISCUSSION AND ANALYSIS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000807397-98-000073.txt</td>\n",
       "      <td>MARK SOLUTIONS INC</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>Item    Management s Discussion and Analysis o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename                        companyname  year  pos  \\\n",
       "0  0000950123-10-115038.txt       American Pacific Corporation  2010    1   \n",
       "1  0000950129-06-002726.txt               FREMONT GENERAL CORP  2005    1   \n",
       "2  0000950134-09-004608.txt  UNITED STATES LIME & MINERALS INC  2008    0   \n",
       "3  0000950152-07-001610.txt                      LUBRIZOL CORP  2006    1   \n",
       "4  0000807397-98-000073.txt                 MARK SOLUTIONS INC  1998    0   \n",
       "\n",
       "                                                text  \n",
       "0  Item   Management s     Discussion and Analysi...  \n",
       "1  Item   Management s Discussion and Analysis of...  \n",
       "2  ITEM       MANAGEMENT S     DISCUSSION AND ANA...  \n",
       "3  ITEM     MANAGEMENT S DISCUSSION AND ANALYSIS ...  \n",
       "4  Item    Management s Discussion and Analysis o...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'] = dataset.filename.apply(extract_MDA)\n",
    "dataset.dropna(inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We split the dataset in train/test ratio: 0.30\n",
    "train_set, test_set = train_test_split(dataset, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6199\n",
      "[u'issuances', u'four', u'payoff', u'increase', u'granting', u'eligible', u'electricity', u'xto', u'chirally', u'sinking', u'regional', u'dell', u'pigment', u'hdtv', u'appropriation', u'bringing', u'internally', u'bioplastics', u'specialties', u'reliable', u'specially', u'paperage', u'feasibility', u'second', u'issuable', u'errors', u'contributed', u'bonuses', u'fossil', u'increasing', u'inducement', u'affiliates', u'reported', u'china', u'affiliated', u'borrowers', u'cyclical', u'k', u'deferring', u'reports', u'military', u'cancellation', u'appropriately', u'classification', u'explained', u'replace', u'brought', u'sizeable', u'unit', u'derivatives']\n"
     ]
    }
   ],
   "source": [
    "train_set_words = []\n",
    "\n",
    "for mda in train_set.text.values:\n",
    "    words = word_tokenize(mda)\n",
    "    for word in words:\n",
    "        stand_word = word.lower() \n",
    "        train_set_words.append(stand_word)\n",
    "\n",
    "all_words = list(set(train_set_words))\n",
    "print(len(all_words))\n",
    "print(all_words[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the baseline model, we just create a bag of words for our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mda_features(mda):\n",
    "    mda_words = word_tokenize(mda.text)\n",
    "    features = {}\n",
    "    stand_mda_words = [word.lower() for word in mda_words]\n",
    "    for word in all_words:\n",
    "        features['contains({})'.format(word)] = word in mda_words\n",
    "    return (features, mda.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_train_set = train_set.apply(mda_features,axis=1)\n",
    "classifier = NB.train(feature_train_set)\n",
    "feature_test_set = test_set.apply(mda_features,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(home) = True                1 : 0      =      8.3 : 1.0\n",
      "       contains(options) = False               0 : 1      =      8.2 : 1.0\n",
      "        contains(unpaid) = True                0 : 1      =      8.2 : 1.0\n",
      "       contains(arising) = True                1 : 0      =      7.5 : 1.0\n",
      "contains(interpretation) = True                1 : 0      =      7.5 : 1.0\n",
      "        contains(hedges) = True                1 : 0      =      7.5 : 1.0\n",
      "       contains(varying) = True                1 : 0      =      6.7 : 1.0\n",
      "         contains(forma) = True                1 : 0      =      6.7 : 1.0\n",
      "      contains(allocate) = True                1 : 0      =      6.7 : 1.0\n",
      "       contains(weather) = True                1 : 0      =      6.7 : 1.0\n",
      "     contains(estimable) = True                1 : 0      =      6.7 : 1.0\n",
      "      contains(software) = True                0 : 1      =      5.9 : 1.0\n",
      "contains(transportation) = True                1 : 0      =      5.9 : 1.0\n",
      "     contains(servicing) = True                1 : 0      =      5.9 : 1.0\n",
      "      contains(overruns) = True                1 : 0      =      5.9 : 1.0\n",
      "         contains(motor) = True                1 : 0      =      5.9 : 1.0\n",
      "          contains(goal) = True                1 : 0      =      5.9 : 1.0\n",
      "      contains(composed) = True                1 : 0      =      5.9 : 1.0\n",
      "      contains(accruals) = True                1 : 0      =      5.9 : 1.0\n",
      "     contains(enhancing) = True                1 : 0      =      5.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.619047619048\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.70      0.64        10\n",
      "          1       0.67      0.55      0.60        11\n",
      "\n",
      "avg / total       0.63      0.62      0.62        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set_pred = classifier.classify_many([fs for (fs, l) in feature_test_set])\n",
    "print(\"Accuracy: {}\".format(classify.accuracy(classifier, feature_test_set)))\n",
    "print(classification_report(test_set.pos, test_set_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0.0          5    1   10\n",
      "1.0          1    0   11\n",
      "All         12    9   35\n"
     ]
    }
   ],
   "source": [
    "tab = pd.crosstab(test_set.pos, pd.DataFrame({'Prediction':test_set_pred}).Prediction, rownames=['Actual'], colnames=['Predicted'],margins=True) # Print confusion matrix\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement number 1: Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mda_features_bis(mda):\n",
    "    mda_words = word_tokenize(mda.text)\n",
    "    stand_mda_words = [word.lower() for word in mda_words]\n",
    "    stand_mda_words = list(set(stand_mda_words))\n",
    "    bigram_finder = BigramCollocationFinder.from_words(stand_mda_words)\n",
    "    score_fn = BigramAssocMeasures.chi_sq\n",
    "    bigrams = bigram_finder.nbest(score_fn, 50)\n",
    "    return (dict([(ngram, True) for ngram in itertools.chain(stand_mda_words, bigrams)]),mda.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_train_set = train_set.apply(mda_features_bis,axis=1)\n",
    "classifier2 = NB.train(feature_train_set)\n",
    "feature_test_set = test_set.apply(mda_features,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          interpretation = True                1 : 0      =      8.3 : 1.0\n",
      "                  unpaid = True                0 : 1      =      8.2 : 1.0\n",
      "                 options = None                0 : 1      =      7.6 : 1.0\n",
      "                 arising = True                1 : 0      =      7.5 : 1.0\n",
      "                  hedges = True                1 : 0      =      7.5 : 1.0\n",
      "                 weather = True                1 : 0      =      6.7 : 1.0\n",
      "                     fin = True                1 : 0      =      6.7 : 1.0\n",
      "                   forma = True                1 : 0      =      6.7 : 1.0\n",
      "                  annual = None                1 : 0      =      6.7 : 1.0\n",
      "                 varying = True                1 : 0      =      6.7 : 1.0\n",
      "               estimable = True                1 : 0      =      6.7 : 1.0\n",
      "                allocate = True                1 : 0      =      6.7 : 1.0\n",
      "               additions = True                0 : 1      =      6.5 : 1.0\n",
      "                       r = True                1 : 0      =      6.4 : 1.0\n",
      "                software = True                0 : 1      =      5.9 : 1.0\n",
      "                       e = True                0 : 1      =      5.9 : 1.0\n",
      "                    task = True                1 : 0      =      5.9 : 1.0\n",
      "                  lender = True                1 : 0      =      5.9 : 1.0\n",
      "                 disrupt = True                1 : 0      =      5.9 : 1.0\n",
      "                accruals = True                1 : 0      =      5.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier2.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47619047619\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      1.00      0.65        10\n",
      "          1       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.23      0.48      0.31        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set_pred = classifier2.classify_many([fs for (fs, l) in feature_test_set])\n",
    "print(\"Accuracy: {}\".format(classify.accuracy(classifier2, feature_test_set)))\n",
    "print(classification_report(test_set.pos, test_set_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  0.0  All\n",
      "Actual             \n",
      "0.0          6   10\n",
      "1.0          1   11\n",
      "All         21   35\n"
     ]
    }
   ],
   "source": [
    "tab = pd.crosstab(test_set.pos, pd.DataFrame({'Prediction':test_set_pred}).Prediction, rownames=['Actual'], colnames=['Predicted'],margins=True) # Print confusion matrix\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement number 2: Reducing feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_fd = FreqDist()\n",
    "label_word_fd = ConditionalFreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in train_set.iterrows():\n",
    "    mdatxt = row[1]['text']\n",
    "    stand_mdatxt = mdatxt.lower()\n",
    "    mda_words = word_tokenize(mdatxt)\n",
    "    word_fd.update(mda_words)\n",
    "    if (row[1]['pos'] ==1):\n",
    "        label_word_fd['pos'].update(mda_words)\n",
    "    else:\n",
    "        label_word_fd['neg'].update(mda_words)\n",
    "    \n",
    "pos_word_count = label_word_fd['pos'].N()\n",
    "neg_word_count = label_word_fd['neg'].N()\n",
    "total_word_count = pos_word_count + neg_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_scores = {}\n",
    " \n",
    "for word, freq in word_fd.iteritems():\n",
    "    pos_score = BigramAssocMeasures.chi_sq(label_word_fd['pos'][word],\n",
    "        (freq, pos_word_count), total_word_count)\n",
    "    neg_score = BigramAssocMeasures.chi_sq(label_word_fd['neg'][word],\n",
    "        (freq, neg_word_count), total_word_count)\n",
    "    word_scores[word] = pos_score + neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'ADD_GRID', u'photo', u'ended', u'paper', u'kiln', u'SFAS', u'PRC', u'Company', u'revenue', u'Gas', u'real', u'increased', u'Augusta', u'joint', u'royalty', u'during', u'colindex', u'WIDTH', u'Advanced', u'End', u'Lubrizol', u'gutter', u'rate', u'year', u'END', u'Type', u'BEGIN', u'lead', u'bottom', u'recorded', u'shares', u'PAGEBREAK', u'Hamilton', u'LLC', u'During', u'Kinross', u'common', u'body', u'Term', u'Natural', u'K', u'million', u'Mt', u'COMMAND', u'loans', u'properties', u'of', u'MH', u'US', u'Pagebreak', u'Arabic', u'No', u'Fremont', u'Ely', u'Arkansas', u'lime', u'Interests', u'RMB', u'pt', u'ASC', u'type', u'medium', u'corrugating', u'gas', u'volume', u'R', u'Noveon', u'solid', u'XBRL', u'project', u'printing', u'exploration', u'venture', u'December', u'property', u'PAGE', u'Lime', u'estate', u'sales', u'Field', u'Revolving', u'border', u'Begin', u'PageNo', u'payments', u'digital', u'stock', u'product', u'Name', u'DHI', u'hang', u'wells', u'segment', u'Page', u'Limestone', u'natural', u'Sequence', u'pension', u'Table', u'the'])\n"
     ]
    }
   ],
   "source": [
    "best = sorted(word_scores.iteritems(), key=lambda (w,s): s, reverse=True)[:100]\n",
    "bestwords = set([w for w, s in best])\n",
    "print bestwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mda_features_ter(mda):\n",
    "    mda_words = word_tokenize(mda.text)\n",
    "    features = {}\n",
    "    stand_mda_words = [word.lower() for word in mda_words]\n",
    "    for word in all_words:\n",
    "        if word in bestwords:\n",
    "            features['contains({})'.format(word)] = word in mda_words\n",
    "    return (features, mda.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_train_set = train_set.apply(mda_features_ter,axis=1)\n",
    "classifier3 = NB.train(feature_train_set)\n",
    "feature_test_set = test_set.apply(mda_features,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(lime) = True                1 : 0      =      5.1 : 1.0\n",
      "          contains(kiln) = True                1 : 0      =      5.1 : 1.0\n",
      "        contains(during) = False               1 : 0      =      4.3 : 1.0\n",
      "            contains(pt) = True                1 : 0      =      4.3 : 1.0\n",
      "         contains(wells) = True                1 : 0      =      4.0 : 1.0\n",
      "      contains(payments) = False               0 : 1      =      3.7 : 1.0\n",
      "       contains(million) = False               0 : 1      =      3.7 : 1.0\n",
      "          contains(body) = True                1 : 0      =      3.5 : 1.0\n",
      "          contains(year) = False               1 : 0      =      3.5 : 1.0\n",
      "       contains(natural) = True                1 : 0      =      3.3 : 1.0\n",
      "           contains(gas) = True                1 : 0      =      3.1 : 1.0\n",
      "        contains(border) = True                1 : 0      =      2.8 : 1.0\n",
      "        contains(bottom) = True                1 : 0      =      2.8 : 1.0\n",
      "       contains(natural) = False               0 : 1      =      2.7 : 1.0\n",
      "         contains(stock) = False               1 : 0      =      2.6 : 1.0\n",
      "         contains(solid) = True                1 : 0      =      2.6 : 1.0\n",
      "       contains(venture) = True                0 : 1      =      2.5 : 1.0\n",
      "       contains(revenue) = False               0 : 1      =      2.5 : 1.0\n",
      "         contains(joint) = True                0 : 1      =      2.5 : 1.0\n",
      "         contains(paper) = True                0 : 1      =      2.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier3.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.571428571429\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.70      0.61        10\n",
      "          1       0.62      0.45      0.53        11\n",
      "\n",
      "avg / total       0.58      0.57      0.57        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set_pred = classifier3.classify_many([fs for (fs, l) in feature_test_set])\n",
    "print(\"Accuracy: {}\".format(classify.accuracy(classifier3, feature_test_set)))\n",
    "print(classification_report(test_set.pos, test_set_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  0.0  1.0  All\n",
      "Actual                  \n",
      "0.0          5    1   10\n",
      "1.0          1    0   11\n",
      "All         13    8   35\n"
     ]
    }
   ],
   "source": [
    "tab = pd.crosstab(test_set.pos, pd.DataFrame({'Prediction':test_set_pred}).Prediction, rownames=['Actual'], colnames=['Predicted'],margins=True) # Print confusion matrix\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement number 3: Multinomial Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We split the dataset in train/test ratio: 0.30\n",
    "train_set, test_set = train_test_split(dataset, test_size = 0.30)\n",
    "# We initiate the classifier\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "counts = vectorizer.fit_transform(train_set.text.values)\n",
    "classifier4 = MultinomialNB(fit_prior=\"False\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior='False')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We fit the training set\n",
    "classifier4.fit(counts, train_set.pos.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's do some prediction on the test set\n",
    "predictions = classifier4.predict(vectorizer.transform(test_set.text.values)) \n",
    "test_set_pred = pd.Series(predictions, index=test_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0  1  All\n",
      "Actual               \n",
      "0           8  3   11\n",
      "1           5  5   10\n",
      "All        13  8   21\n"
     ]
    }
   ],
   "source": [
    "tab = pd.crosstab(test_set.pos, test_set_pred, rownames=['Actual'], colnames=['Predicted'], margins=True) # Print confusion matrix\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print tab['All']['All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.619048\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.73      0.67        11\n",
      "          1       0.62      0.50      0.56        10\n",
      "\n",
      "avg / total       0.62      0.62      0.61        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"Accuracy: %f\" %(np.float(tab[0][0]+tab[1][1])/(tab['All']['All']))\n",
    "print(classification_report(test_set.pos, test_set_pred)) # Print accuracy, precision, recall, F measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Improvement number 4: Use the Loughran McDonald dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corp=[]\n",
    "filenames=[]\n",
    "\n",
    "for name in dataset['filename']:\n",
    "      filenames.append(name)\n",
    "      corp.append(extract_MDA(name))\n",
    "\n",
    "filenames=[j for j in filenames if corp[filenames.index(j)] is not None]\n",
    "corp = [i for i in corp if i is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word', min_df = 0, stop_words = 'english')\n",
    "tfidf_matrix =  tf.fit_transform(corp)\n",
    "feature_names = tf.get_feature_names() \n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_array)\n",
    "tfidf_df.columns = [i.upper() for i in feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Positive score for document ', 0, ' is: ', 0.20953324040533489)\n",
      "('Positive score for document ', 1, ' is: ', 0.20228559947637748)\n",
      "('Positive score for document ', 2, ' is: ', 0.26371396239930872)\n",
      "('Positive score for document ', 3, ' is: ', 0.0)\n",
      "('Positive score for document ', 4, ' is: ', 0.2865921862948797)\n",
      "('Positive score for document ', 5, ' is: ', 0.24003066534384965)\n",
      "('Positive score for document ', 6, ' is: ', 0.22206673653978737)\n",
      "('Positive score for document ', 7, ' is: ', 0.24122032881602809)\n",
      "('Positive score for document ', 8, ' is: ', 0.15486669311879703)\n",
      "('Positive score for document ', 9, ' is: ', 0.22035068466832977)\n",
      "('Positive score for document ', 10, ' is: ', 0.24430912547070144)\n",
      "('Positive score for document ', 11, ' is: ', 0.23427609002113481)\n",
      "('Positive score for document ', 12, ' is: ', 0.21887508617275797)\n",
      "('Positive score for document ', 13, ' is: ', 0.12418245071841545)\n",
      "('Positive score for document ', 14, ' is: ', 0.39043351240235574)\n",
      "('Positive score for document ', 15, ' is: ', 0.41763546989594363)\n",
      "('Positive score for document ', 16, ' is: ', 0.16102496906456895)\n",
      "('Positive score for document ', 17, ' is: ', 0.17279638438649406)\n",
      "('Positive score for document ', 18, ' is: ', 0.11937443741342282)\n",
      "('Positive score for document ', 19, ' is: ', 0.16400260095215133)\n",
      "('Positive score for document ', 20, ' is: ', 0.326632260883852)\n",
      "('Positive score for document ', 21, ' is: ', 0.22686850806886733)\n",
      "('Positive score for document ', 22, ' is: ', 0.22190555241541216)\n",
      "('Positive score for document ', 23, ' is: ', 0.14999393998138785)\n",
      "('Positive score for document ', 24, ' is: ', 0.30695749973645492)\n",
      "('Positive score for document ', 25, ' is: ', 0.38192399604101873)\n",
      "('Positive score for document ', 26, ' is: ', 0.45342599456996241)\n",
      "('Positive score for document ', 27, ' is: ', 0.3556597711940927)\n",
      "('Positive score for document ', 28, ' is: ', 0.29426392465430556)\n",
      "('Positive score for document ', 29, ' is: ', 0.12348538456397411)\n",
      "('Positive score for document ', 30, ' is: ', 0.29481113460792563)\n",
      "('Positive score for document ', 31, ' is: ', 0.31016454238726282)\n",
      "('Positive score for document ', 32, ' is: ', 0.21743930014850957)\n",
      "('Positive score for document ', 33, ' is: ', 0.24452099760115753)\n",
      "('Positive score for document ', 34, ' is: ', 0.23665807704874789)\n",
      "('Positive score for document ', 35, ' is: ', 0.24701539156182925)\n",
      "('Positive score for document ', 36, ' is: ', 0.30617865470651212)\n",
      "('Positive score for document ', 37, ' is: ', 0.30435180429237407)\n",
      "('Positive score for document ', 38, ' is: ', 0.38595337120519224)\n",
      "('Positive score for document ', 39, ' is: ', 0.3593236964062298)\n",
      "('Positive score for document ', 40, ' is: ', 0.24080051454522597)\n",
      "('Positive score for document ', 41, ' is: ', 0.30926349362999239)\n",
      "('Positive score for document ', 42, ' is: ', 0.43159315065842035)\n",
      "('Positive score for document ', 43, ' is: ', 0.34352742952459936)\n",
      "('Positive score for document ', 44, ' is: ', 0.30558949191237711)\n",
      "('Positive score for document ', 45, ' is: ', 0.2958260259940409)\n",
      "('Positive score for document ', 46, ' is: ', 0.16621420428047132)\n",
      "('Positive score for document ', 47, ' is: ', 0.095576099113364649)\n",
      "('Positive score for document ', 48, ' is: ', 0.13120015711931754)\n",
      "('Positive score for document ', 49, ' is: ', 0.076128107623421815)\n",
      "('Positive score for document ', 50, ' is: ', 0.12355611489205762)\n",
      "('Positive score for document ', 51, ' is: ', 0.26571305246782861)\n",
      "('Positive score for document ', 52, ' is: ', 0.27436878969873735)\n",
      "('Positive score for document ', 53, ' is: ', 0.25160485321752402)\n",
      "('Positive score for document ', 54, ' is: ', 0.31931698982288975)\n",
      "('Positive score for document ', 55, ' is: ', 0.24223095519784035)\n",
      "('Positive score for document ', 56, ' is: ', 0.20386106025121131)\n",
      "('Positive score for document ', 57, ' is: ', 0.22193671310714835)\n",
      "('Positive score for document ', 58, ' is: ', 0.20669296661581474)\n",
      "('Positive score for document ', 59, ' is: ', 0.12988061088150876)\n",
      "('Positive score for document ', 60, ' is: ', 0.030417860864723929)\n",
      "('Positive score for document ', 61, ' is: ', 0.025605911251339784)\n",
      "('Positive score for document ', 62, ' is: ', 0.011091453311307902)\n",
      "('Positive score for document ', 63, ' is: ', 0.023230213750995193)\n",
      "('Positive score for document ', 64, ' is: ', 0.022446906026953158)\n",
      "('Positive score for document ', 65, ' is: ', 0.02222686399679754)\n",
      "('Positive score for document ', 66, ' is: ', 0.022157831669056358)\n",
      "('Negative score for document ', 0, ' is: ', -0.24608296675081165)\n",
      "('Negative score for document ', 1, ' is: ', -0.34841678607492088)\n",
      "('Negative score for document ', 2, ' is: ', -0.45063083535867893)\n",
      "('Negative score for document ', 3, ' is: ', -0.12059511727175308)\n",
      "('Negative score for document ', 4, ' is: ', -0.21273083231537079)\n",
      "('Negative score for document ', 5, ' is: ', -0.22524832605193179)\n",
      "('Negative score for document ', 6, ' is: ', -0.22849149898683091)\n",
      "('Negative score for document ', 7, ' is: ', -0.52268102839556774)\n",
      "('Negative score for document ', 8, ' is: ', -0.74268619086212395)\n",
      "('Negative score for document ', 9, ' is: ', -0.31626769973351992)\n",
      "('Negative score for document ', 10, ' is: ', -0.34614338450148691)\n",
      "('Negative score for document ', 11, ' is: ', -0.22693431191448801)\n",
      "('Negative score for document ', 12, ' is: ', -0.21695326251140051)\n",
      "('Negative score for document ', 13, ' is: ', -0.28689497307137968)\n",
      "('Negative score for document ', 14, ' is: ', -0.80718321227591616)\n",
      "('Negative score for document ', 15, ' is: ', -0.70373745772103358)\n",
      "('Negative score for document ', 16, ' is: ', -0.48560108581492084)\n",
      "('Negative score for document ', 17, ' is: ', -0.37925404918560041)\n",
      "('Negative score for document ', 18, ' is: ', -0.39561243168563964)\n",
      "('Negative score for document ', 19, ' is: ', -0.41321846548187607)\n",
      "('Negative score for document ', 20, ' is: ', -0.95307752507141574)\n",
      "('Negative score for document ', 21, ' is: ', -0.80593019484941752)\n",
      "('Negative score for document ', 22, ' is: ', -0.87340351549085271)\n",
      "('Negative score for document ', 23, ' is: ', -1.1979594233236182)\n",
      "('Negative score for document ', 24, ' is: ', -0.77630877931091835)\n",
      "('Negative score for document ', 25, ' is: ', -0.70423279559250551)\n",
      "('Negative score for document ', 26, ' is: ', -0.59155580298969723)\n",
      "('Negative score for document ', 27, ' is: ', -0.71811041215110172)\n",
      "('Negative score for document ', 28, ' is: ', -0.19629228400225843)\n",
      "('Negative score for document ', 29, ' is: ', -0.23380636669266455)\n",
      "('Negative score for document ', 30, ' is: ', -0.37426880492632647)\n",
      "('Negative score for document ', 31, ' is: ', -0.97448734710111584)\n",
      "('Negative score for document ', 32, ' is: ', -0.55694301717571115)\n",
      "('Negative score for document ', 33, ' is: ', -0.64375932766237565)\n",
      "('Negative score for document ', 34, ' is: ', -0.34910562876582818)\n",
      "('Negative score for document ', 35, ' is: ', -0.3501584567830564)\n",
      "('Negative score for document ', 36, ' is: ', -0.30977215221052334)\n",
      "('Negative score for document ', 37, ' is: ', -0.29550054253457553)\n",
      "('Negative score for document ', 38, ' is: ', -0.87189625671387561)\n",
      "('Negative score for document ', 39, ' is: ', -0.68386188621239608)\n",
      "('Negative score for document ', 40, ' is: ', -0.59320301128036468)\n",
      "('Negative score for document ', 41, ' is: ', -0.39139083022256826)\n",
      "('Negative score for document ', 42, ' is: ', -0.39396873476070299)\n",
      "('Negative score for document ', 43, ' is: ', -0.47351004062061153)\n",
      "('Negative score for document ', 44, ' is: ', -0.52007325640373736)\n",
      "('Negative score for document ', 45, ' is: ', -0.81226364444700927)\n",
      "('Negative score for document ', 46, ' is: ', -0.49601211339570012)\n",
      "('Negative score for document ', 47, ' is: ', -0.23971016548637933)\n",
      "('Negative score for document ', 48, ' is: ', -0.30091609203112468)\n",
      "('Negative score for document ', 49, ' is: ', -0.23351775555851512)\n",
      "('Negative score for document ', 50, ' is: ', -0.24579616628601481)\n",
      "('Negative score for document ', 51, ' is: ', -0.51376299140859005)\n",
      "('Negative score for document ', 52, ' is: ', -0.54708227875364646)\n",
      "('Negative score for document ', 53, ' is: ', -0.47671870116496728)\n",
      "('Negative score for document ', 54, ' is: ', -0.47930449866758679)\n",
      "('Negative score for document ', 55, ' is: ', -0.46024952899386273)\n",
      "('Negative score for document ', 56, ' is: ', -0.48037608741511917)\n",
      "('Negative score for document ', 57, ' is: ', -0.45622533480990413)\n",
      "('Negative score for document ', 58, ' is: ', -0.47070606729790565)\n",
      "('Negative score for document ', 59, ' is: ', -0.36127134992894183)\n",
      "('Negative score for document ', 60, ' is: ', -0.14790911294362516)\n",
      "('Negative score for document ', 61, ' is: ', -0.17357164849566617)\n",
      "('Negative score for document ', 62, ' is: ', -0.18428463432695613)\n",
      "('Negative score for document ', 63, ' is: ', -0.11295864376134483)\n",
      "('Negative score for document ', 64, ' is: ', -0.10914975163904211)\n",
      "('Negative score for document ', 65, ' is: ', -0.1080797808861554)\n",
      "('Negative score for document ', 66, ' is: ', -0.1077441060533313)\n"
     ]
    }
   ],
   "source": [
    "dict = pd.read_excel(\"LoughranMcDonald_MasterDictionary_2014.xlsx\")\n",
    "minidict = dict[dict['Word'].isin(tfidf_df.columns)] \n",
    "minidict = minidict.set_index('Word')\n",
    "minidict.loc[minidict['Positive']>0, 'Positive'] = 1\n",
    "minidict.loc[minidict['Negative']>0, 'Negative'] = -1\n",
    "tfidf_df = tfidf_df.T \n",
    "tfidf_df.index.name='Word'\n",
    "\n",
    "result_df = pd.merge(tfidf_df, minidict, how='left', left_index=True, right_index=True)\n",
    "result_df = result_df[np.isfinite(result_df['Negative'])]\n",
    "    \n",
    "\n",
    "for i in range(0, len(corp)):\n",
    "    print('Positive score for document ',i,' is: ', sum(result_df[i]*result_df['Positive']))\n",
    "\n",
    "for i in range(0, len(corp)):\n",
    "    print('Negative score for document ',i,' is: ', sum(result_df[i]*result_df['Negative']))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Result=[]\n",
    "for i in range(0, len(corp)):\n",
    "    Result.append(sum(result_df[i]*result_df['Positive'])+sum(result_df[i]*result_df['Negative']))\n",
    "    if Result[i]<0:\n",
    "        Result[i]=0\n",
    "    else:\n",
    "        Result[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(result,label):\n",
    "    bib=0\n",
    "    for i in range(1,len(result)):\n",
    "        if (result[i]==label[i]):\n",
    "            bib=bib+1\n",
    "    acc=np.float(bib)/len(result)\n",
    "    return acc,bib\n",
    "labels=[]\n",
    "for label in dataset['pos']:\n",
    "    labels.append(label)\n",
    "a=accuracy(Result,labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Loughran McDonald dictionary model  : 0.507463\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "for label in dataset['pos']:\n",
    "    labels.append(label)\n",
    "a=accuracy(Result,labels)  \n",
    "print \"The accuracy for the Loughran McDonald dictionary model  : %f\" %a[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
